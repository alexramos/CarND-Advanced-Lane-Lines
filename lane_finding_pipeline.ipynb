{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Advanced Lane Finding Project - Pipeline Implementation\n",
    "\n",
    "In this notebook, I implement an advanced lane finding pipline and run it on a example video.\n",
    "\n",
    "**Pipeline steps:**\n",
    "\n",
    "1. Undistort image with saved camera calibrations\n",
    "2. \"Binarize\" image using color and gradient\n",
    "3. Fit lane lines using A. (scanning) or B. (look-ahead filter) approaches\n",
    "    1. Scan image for lane pixels using windowed approach\n",
    "    2. Search for lane pixels around existing fit\n",
    "4. Perform sanity check on lane-line fits\n",
    "    1. Ensure lines are reasonable distance apart\n",
    "    2. Ensure lines are roughly parallel\n",
    "5. Draw lane fit onto image\n",
    "\n",
    "\n",
    "- When fitting lane lines, approach B. (look-ahead filter) is used if previous good fits exists in memory.\n",
    "- For drawing the detected lane, the output is smoothed over the previous 30 frames.\n",
    "- If sanity check fails for a fit, the last good fit is used.  If sanity check fails 15 consecutive frames, the pipeline falls back to searching for a fit using approach A. (scanning).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os.path as osp\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import helper functions form utils.py\n",
    "from utils import get_binary_img, warper, draw_detected_lane\n",
    "from utils import fit_lane_lines, fit_lane_lines_from_previous_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "YM_PER_PIX = 30 / 720 # meters per pixel in y dimension\n",
    "XM_PER_PIX = 3.7 / 700 # meters per pixel in x dimension\n",
    "IMSHAPE = 1280, 720 # hardcoded\n",
    "\n",
    "class Line():\n",
    "    \"\"\"A class to receive the characteristics of each line detection\"\"\"\n",
    "    \n",
    "    def __init__(self, buffer_size=30):        \n",
    "        # number of previous fits to store\n",
    "        self.buffer_size = buffer_size \n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque(maxlen=self.buffer_size) \n",
    "        \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "\n",
    "        #y values for detected line pixels\n",
    "        self.ally = np.linspace(0, IMSHAPE[0]-1, IMSHAPE[0])\n",
    "        \n",
    "    def update_fit(self, fit):\n",
    "        self.current_fit = fit\n",
    "        self.recent_xfitted.append(fit)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.recent_xfitted.clear()\n",
    "        self.current_fit = [np.array([False])]  \n",
    "           \n",
    "    @property\n",
    "    def detected(self):\n",
    "        \"\"\"was the line detected in the last iteration?\"\"\"\n",
    "        return len(self.recent_xfitted) > 0\n",
    "    \n",
    "    @property\n",
    "    def best_fit(self):\n",
    "        \"\"\"polynomial coefficients averaged over the last n iterations\"\"\"\n",
    "        return np.array(self.recent_xfitted).sum(axis=0) / len(self.recent_xfitted)\n",
    "\n",
    "    @property\n",
    "    def allx(self):\n",
    "        \"\"\"x values for detected line pixels\"\"\"\n",
    "        return self.current_fit[0]*self.ally**2 + self.current_fit[1]*self.ally + self.current_fit[2]\n",
    "    \n",
    "    @property\n",
    "    def bestx(self):\n",
    "        \"\"\"average x values of the fitted line over the last n iterations\"\"\"\n",
    "        return self.best_fit[0]*self.ally**2 + self.best_fit[1]*self.ally + self.best_fit[2]\n",
    "    \n",
    "    @property\n",
    "    def radius_of_curvature(self):\n",
    "        \"\"\"radius of curvature of the line in some units\"\"\"\n",
    "        y_eval = np.max(self.ally)\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        fit_cr = np.polyfit(self.ally*YM_PER_PIX, self.bestx*XM_PER_PIX, 2)\n",
    "        # Calculate the new radii of curvature\n",
    "        curverad = ((1 + (2*fit_cr[0]*y_eval*YM_PER_PIX + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "        return curverad\n",
    "        \n",
    "    @property\n",
    "    def line_base_pos(self):\n",
    "        \"\"\"position in pixels of line at bottom of image\"\"\"\n",
    "        y_eval = np.max(self.ally)\n",
    "        return self.best_fit[0]*y_eval**2 + self.best_fit[1]*y_eval + self.best_fit[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "n_invalid_fits = 0\n",
    "\n",
    "# camera calibration and trasform matrices\n",
    "mtx, dist = pickle.load(open('camera_cal.pkl', 'rb'))\n",
    "\n",
    "def sanity_check_fits(left_fit, right_fit, lane_width_bounds=(2.5, 5.0), parallel_thresh=100):\n",
    "    \"\"\"Performs follwing sanity checks on fits:\n",
    "        1. Determine if fits yield lane width that is between `lane_width_bounds`\n",
    "        \n",
    "        2. Determine if lines are roughly parallel.\n",
    "        \n",
    "        Function returns `True` if all sanity checks are met.\n",
    "    \"\"\"\n",
    "    fit_is_sane = True\n",
    "    calc_x_bottom = lambda fit: fit[0]*1279**2 + fit[1]*1279 + fit[2] \n",
    "    calc_x_top = lambda fit: fit[0]*0**2 + fit[1]*0 + fit[2] \n",
    "\n",
    "    bot_diff = calc_x_bottom(right_fit) - calc_x_bottom(left_fit)\n",
    "    top_diff = calc_x_top(right_fit) - calc_x_top(left_fit)\n",
    "\n",
    "    # lane width in meters\n",
    "    lane_width = bot_diff * XM_PER_PIX \n",
    "    \n",
    "    # difference between lane width (in pixels) at bottom of image\n",
    "    # and lane width at top of image\n",
    "    parallel_diff = top_diff - bot_diff \n",
    "    \n",
    "    if lane_width < lane_width_bounds[0] or lane_width > lane_width_bounds[1]:\n",
    "        fit_is_sane = False\n",
    "    elif abs(parallel_diff) > parallel_thresh:\n",
    "        fit_is_sane = False\n",
    "        \n",
    "    return fit_is_sane\n",
    "\n",
    "def process_image(image, reset_thresh=15):\n",
    "    global n_invalid_fits\n",
    "    \n",
    "    # undistort image\n",
    "    image = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    binary_img = get_binary_img(image)\n",
    "    binary_warped_img = warper(binary_img)\n",
    "    \n",
    "    if not left_line.detected or not right_line.detected:\n",
    "        # previous line was not detected for new fits\n",
    "        left_fit, right_fit, _ = fit_lane_lines(binary_warped_img)\n",
    "    else:\n",
    "        # previous frame yielded a valid fit, search around it\n",
    "        left_fit, right_fit = fit_lane_lines_from_previous_fit(binary_warped_img,\n",
    "            left_line.best_fit, right_line.best_fit)\n",
    "    \n",
    "    # Sanity check\n",
    "    fit_is_sane = sanity_check_fits(left_fit, right_fit)\n",
    "     \n",
    "    if fit_is_sane:\n",
    "        # if qc passess, update fit\n",
    "        left_line.update_fit(left_fit)\n",
    "        right_line.update_fit(right_fit)\n",
    "        n_invalid_fits = 0 # reset \n",
    "    else:\n",
    "        n_invalid_fits += 1\n",
    "        \n",
    "        if n_invalid_fits == reset_thresh:\n",
    "            n_invalid_fits = 0\n",
    "            # if qc fails for `reset_thresh` consecutive times, clear cache\n",
    "            left_line.clear()\n",
    "            right_line.clear()\n",
    "    \n",
    "    if left_line.detected and right_line.detected:\n",
    "        left_line.update_fit(left_fit)\n",
    "        right_line.update_fit(right_fit)\n",
    "\n",
    "        out_img = draw_detected_lane(image, binary_warped_img,\n",
    "             left_line.ally, left_line.bestx, right_line.bestx)    \n",
    "\n",
    "        # Write text on output image\n",
    "        avg_curverad = (left_line.radius_of_curvature +  right_line.radius_of_curvature) / 2\n",
    "        rad_str = 'Radius of Curvature = %dm' % np.round(avg_curverad)\n",
    "\n",
    "        lane_center_px = (left_line.line_base_pos + right_line.line_base_pos) / 2\n",
    "        lane_center_offset_px = lane_center_px - (binary_warped_img.shape[1] / 2)\n",
    "        lane_center_offset_m = lane_center_offset_px * XM_PER_PIX\n",
    "        offset_str = 'Vehicle is %.2fm off center of lane' % lane_center_offset_m\n",
    "\n",
    "        cv2.putText(out_img, rad_str, (40, 75), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1, (255, 255, 255), 2)\n",
    "        cv2.putText(out_img, offset_str, (40, 150), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1, (255, 255, 255), 2)\n",
    "        \n",
    "    else:\n",
    "        out_img = image\n",
    "        cv2.putText(out_img, 'Unable to fit lane lines!', (40, 75),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/project_video_output.mp4\n",
      "[MoviePy] Writing video output_images/project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [11:29<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/project_video_output.mp4 \n",
      "\n",
      "CPU times: user 13min 16s, sys: 1min 9s, total: 14min 25s\n",
      "Wall time: 11min 30s\n"
     ]
    }
   ],
   "source": [
    "# process vid\n",
    "output_vid = 'project_video_output.mp4'\n",
    "input_clip = VideoFileClip('project_video.mp4')\n",
    "processed_clip = input_clip.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time processed_clip.write_videofile(output_vid, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_vid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
